{
  "criteria": [
    "**Skills:**",
    "*   **LLM Expertise:**",
    "*   Prompt Engineering",
    "*   Fine-tuning LLMs",
    "*   Deploying LLM-driven applications (Chatbots, Summarization, RAG systems, Structured Data Extraction)",
    "*   **RAG & Vector Databases:**",
    "*   RAG Implementations",
    "*   Vector Database Operations (Azure AI Search, Pinecone, FAISS, PgVector)",
    "*   **API Development:**",
    "*   FastAPI",
    "*   Developing robust APIs and microservices to integrate multiple LLM providers (Azure OpenAI, Anthropic, Mistral)",
    "*   Streaming responses",
    "*   Fallback mechanisms",
    "*   **MLOps & CI/CD:**",
    "*   MLOps practices for managing AI workflows",
    "*   Deploying scalable pipelines",
    "*   Docker, Kubernetes",
    "*   CI/CD pipelines for model deployment",
    "*   A/B testing frameworks",
    "*   Observability solutions (tracking model quality, performance, costs)",
    "*   **Cloud Computing:**",
    "*   Azure cloud services",
    "*   **Database Proficiency:**",
    "*   SQL and NoSQL databases (Azure Cosmos DB)",
    "*   **Programming & Frameworks:**",
    "*   OpenAI-Python",
    "*   LangChain",
    "*   LiteLLM",
    "*   Pydantic",
    "*   **AI Solution Architecture:**",
    "*   Designing architectures for complex AI applications combining LLMs, embedding models, and vector stores.",
    "*   Semantic caching",
    "*   Hybrid search",
    "*   Custom routing logic",
    "*   Ensuring security, reliability, and cost optimization",
    "**Experience:**",
    "*   Hands-on experience with prompt engineering, fine-tuning, and deploying LLM-driven applications",
    "*   Experience with OpenAI-Python, LiteLLM, Pydentic and related frameworks",
    "*   AI Application Development: Design and implement end-to-end AI solutions using OpenAI-Python, LangChain, LiteLLM, and custom frameworks. Build production-grade applications integrating RAG systems, chatbots, and text summarization while optimizing for quality, latency and cost using techniques like model quantization and caching.",
    "*   LLM Integration & API Development: Develop robust APIs and microservices using FastAPI to integrate multiple LLM providers (Azure OpenAI, Anthropic, Mistral). Create scalable vector search solutions using Azure AI Search/Pinecone/PgVector, implement streaming responses, and build reliable fallback mechanisms for production environments.",
    "*   MLOps & Infrastructure: Deploy and monitor AI applications using Docker, Kubernetes, in Azure cloud services. Build automated CI/CD pipelines for model deployment, implement A/B testing frameworks, and develop observability solutions for tracking model quality, performance and costs.",
    "**Qualifications:**",
    "*   Strong understanding of Azure OpenAI and Azure AI Search.",
    "**Certifications (Nice-to-Have):**",
    "*   Azure Certifications such as Microsoft Certified: Azure AI Engineer Associate or Azure Solutions Architect Expert."
  ],
  "criteria_type": "overall"
}